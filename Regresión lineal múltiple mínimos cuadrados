# Importamos las herramientas necesarias para el código.
import pandas as pd
import numpy as np
from scipy.stats import t
from sklearn.preprocessing import StandardScaler

	''' Cargamos el dataset con todas las observaciones del vino blanco, para realizar la estimación del modelo de regresión lineal múltiple utilizando el método de mínimos cuadrados. '''

vinos = pd.read_csv("winequality-white.csv", sep=";")

# Definimos las variables predictoras (X) y la variable respuesta (Y).
X = vinos[["fixed acidity", "volatile acidity", "citric acid", "residual sugar", "density", "pH", "alcohol"]].values
Y = vinos["quality"].values.reshape(-1, 1)

	''' Agregamos una columna de unos al principio de la matriz X 
para representar el intercepto β₀. '''
n, p = X_std.shape
X_design = np.hstack((np.ones((n, 1)), X_std))

	''' Aplicamos la ecuación matricial del modelo de regresión lineal múltiple: β̂ = (XᵀX)⁻¹ XᵀY → con esta fórmula obtenemos directamente los coeficientes que minimizan la suma de los errores cuadráticos. '''
beta = np.linalg.inv(X_design.T @ X_design) @ X_design.T @ Y

	''' Calculamos los valores ajustados ŷ, es decir, las predicciones del modelo para cada observación del dataset. '''
y_hat = X_design @ beta

	''' Calculamos los residuos (diferencia entre los valores reales y los estimados). '''
resid = Y - y_hat
	''' Estimamos la varianza residual, que mide el error medio del modelo.'''
sigma2_hat = (resid.T @ resid) / (n - p - 1)

	''' Calculamos el coeficiente de determinación (R²) y el R² ajustado, estas indican el grado en que las variables predictoras explican la variabilidad de Y. '''
SST = np.sum((Y - Y.mean())**2)
SSE = np.sum(resid**2)
R2 = 1 - SSE / SST
R2_adj = 1 - (1 - R2) * (n - 1) / (n - p - 1)

	''' Estimamos los errores estándar de los coeficientes para evaluar su precisión. '''
cov_beta = sigma2_hat[0,0] * np.linalg.inv(X_design.T @ X_design)
se_beta = np.sqrt(np.diag(cov_beta))

	''' Calculamos los valores t y los p-valores. '''
t_values = beta.flatten() / se_beta
p_values = 2 * (1 - t.cdf(np.abs(t_values), df=n - p - 1))
	''' Reunimos los resultados principales del modelo. '''

resultados = {
    "β̂": beta.flatten(),
    "σ̂²": sigma2_hat[0, 0],
    "R²": R2,
    "R² ajustado": R2_adj,
    "ŷ": y_hat.flatten(),
    "residuos": resid.flatten(),
}

	''' Creamos una tabla resumen que contiene las variables, sus coeficientes, errores estándar, valores t y p-valores. '''
variables = ["Intercepto"] + ["fixed acidity", "volatile acidity", "citric acid", "residual sugar", "density", "pH", "alcohol"]
tabla = pd.DataFrame({
    "Variable": variables,
    "β̂": beta.flatten(),
    "Error estándar": se_beta,
    "t": t_values,
    "p-valor": p_values
})

''' Para terminar, imprimimos los resultados generales y los coeficientes del modelo. '''
print("Resultados Generales")
for k, v in resultados.items():
    if isinstance(v, float) or isinstance(v, np.float64):
        print(f"{k}: {v:.4f}")
    elif isinstance(v, np.ndarray):
        print(f"{k}: array con {len(v)} valores")
print("\n Coeficientes del Modelo")
print(tabla.round(4))
